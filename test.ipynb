{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a849646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.test import BabelWindowedDataset, BabelDatasetSplit\n",
    "from src.data.motion import AMASSMotionLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cba6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def create_simple_motion_loader(amass_base_dir: str):\n",
    "    \"\"\"\n",
    "    Create a simple motion loader function.\n",
    "    This is an example - you'll need to adapt this to your specific motion data format.\n",
    "    \"\"\"\n",
    "    def motion_loader(path: str, start: float, end: float):\n",
    "        # Construct full path to motion file\n",
    "        full_path = os.path.join(amass_base_dir, path)\n",
    "        \n",
    "        # This is a placeholder - replace with your actual motion loading logic\n",
    "        # For example, if you have .npy files:\n",
    "        # motion_data = np.load(full_path)\n",
    "        # start_frame = int(start * fps)\n",
    "        # end_frame = int(end * fps)\n",
    "        # return {'motion': motion_data[start_frame:end_frame]}\n",
    "        \n",
    "        # Placeholder return\n",
    "        fps = 20.0\n",
    "        num_frames = int((end - start) * fps)\n",
    "        return {\n",
    "            'motion': torch.randn(num_frames, 135),  # Example: 135D motion features\n",
    "            'fps': fps,\n",
    "            'num_frames': num_frames\n",
    "        }\n",
    "    \n",
    "    return motion_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c658fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_loader = create_simple_motion_loader(\"/home/nadir/disk/codes/human-ml3d-code/amass_data\")\n",
    "motion_loader = AMASSMotionLoader(\n",
    "    base_dir=\"/home/nadir/disk/codes/human-ml3d-code/amass_data\",\n",
    "    fps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d106c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6615 samples from train.json\n",
      "Loaded 6615 sequences\n",
      "Created 1145975 windows\n",
      "Window size: 20 frames (1.00s)\n",
      "Window stride: 1 frames (0.05s)\n",
      "Loaded 2193 samples from val.json\n",
      "Loaded 2193 sequences\n",
      "Created 13991 windows\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create motion loader\n",
    "    \n",
    "    # Create dataset with windowing\n",
    "    dataset = BabelWindowedDataset(\n",
    "        babel_dir=\"/home/nadir/disk/codes/locate/src/babel_tools/babel_v1.0_release\",\n",
    "        motion_loader=motion_loader,\n",
    "        window_size=20,  # 60 frames = 3 seconds at 20fps\n",
    "        window_stride=1,  # 20 frames = 1 second stride\n",
    "        splits=BabelDatasetSplit.TRAIN,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Create dataset without windowing (whole sequences)\n",
    "    full_seq_dataset = BabelWindowedDataset(\n",
    "        babel_dir=\"/home/nadir/disk/codes/locate/src/babel_tools/babel_v1.0_release\",\n",
    "        motion_loader=motion_loader,\n",
    "        window_size=-1,  # No windowing\n",
    "        splits=BabelDatasetSplit.VAL,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # # Get statistics\n",
    "    # stats = dataset.get_label_statistics()\n",
    "    # print(\"Label distribution:\", stats['labels'])\n",
    "    \n",
    "    # # Filter by specific labels\n",
    "    # walking_dataset = dataset.filter_by_labels(['walk', 'walking'])\n",
    "    \n",
    "    # # Access a sample\n",
    "    # sample = dataset[0]\n",
    "    # print(\"Sample keys:\", sample.keys())\n",
    "    # print(\"Motion shape:\", sample['motion_data']['motion'].shape)\n",
    "    # print(\"Label:\", sample['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63d7ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 263])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"motion_data\"][\"x\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01848084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[processing]::   1%|          | 13219/1145975 [00:21<30:17, 623.10it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(iterable\u001b[38;5;241m=\u001b[39mdataset, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[processing]:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     _\n",
      "File \u001b[0;32m~/tmr-code/.tmr.venv/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/tmr-code/src/data/test.py:232\u001b[0m, in \u001b[0;36mBabelWindowedDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    229\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequences[window[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Load motion data using the provided motion loader\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m motion_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmotion_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamass_file_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Prepare output\u001b[39;00m\n\u001b[1;32m    239\u001b[0m output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotion_data\u001b[39m\u001b[38;5;124m'\u001b[39m: motion_data,\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: window[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation_type\u001b[39m\u001b[38;5;124m'\u001b[39m: window[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    250\u001b[0m }\n",
      "File \u001b[0;32m~/tmr-code/src/data/motion.py:27\u001b[0m, in \u001b[0;36mAMASSMotionLoader.__call__\u001b[0;34m(self, path, start, end)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotions:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# motion_path = os.path.join(self.base_dir, path + \".npy\")\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# motion_path = os.path.join(self.base_dir, path + \".guoh3dfeats.npy\")\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# motion_path = os.path.join(self.base_dir, path + \"_transformed.npz\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     motion_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dir, path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_transformed.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     motion \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmotion_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     motion \u001b[38;5;241m=\u001b[39m motion[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_joint_vecs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m     motion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(motion)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/tmr-code/.tmr.venv/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:458\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    456\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    457\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 458\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m magic:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data left in file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sample in tqdm.tqdm(iterable=dataset, total=len(dataset), desc=\"[processing]:\"):\n",
    "    _   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4202b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a130344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570289"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"/home/nadir/windowed-babel-for-classification-for-training/20-1/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a56ca937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[len(dataset)]: 1145975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'motion_data': {'motion': tensor([[ 0.4963,  0.4687,  0.2265,  ..., -1.6615, -1.3828,  0.2366],\n",
       "          [ 0.3379, -1.2403,  1.0613,  ...,  0.1124,  0.5131, -1.0264],\n",
       "          [-1.8594,  0.9147,  0.9663,  ..., -0.4648, -1.2133, -1.3539],\n",
       "          ...,\n",
       "          [-0.7037, -0.7478,  0.6335,  ...,  0.7342,  0.0263, -0.1953],\n",
       "          [ 0.5741,  1.0680, -0.9120,  ..., -1.1923, -0.8744,  2.0031],\n",
       "          [ 1.3678, -0.1304,  0.3780,  ..., -0.0623, -0.2185, -0.6344]]),\n",
       "  'fps': 20.0,\n",
       "  'num_frames': 19},\n",
       " 'label': 'walk',\n",
       " 'act_cat': ['walk'],\n",
       " 'raw_label': 'walking',\n",
       " 'start_time': 0.4,\n",
       " 'end_time': 1.4,\n",
       " 'duration': 1.0,\n",
       " 'sid': '7666',\n",
       " 'window_type': 'sliding_window',\n",
       " 'annotation_type': 'sequence',\n",
       " 'start_frame': 8,\n",
       " 'end_frame': 28,\n",
       " 'window_size': 20,\n",
       " 'window_stride': 1,\n",
       " 'parent_annotation_start': 0,\n",
       " 'parent_annotation_end': 3.6}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"[len(dataset)]:\", len(dataset))\n",
    "\n",
    "index = np.random.randint(0, len(dataset))\n",
    "\n",
    "dataset[index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tmr.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
