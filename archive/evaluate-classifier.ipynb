{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869901ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6660b149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadir/disk/codes/tmr-code/.tmr.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tqdm\n",
    "import json\n",
    "import torch\n",
    "import hydra\n",
    "import pprint\n",
    "import logging\n",
    "import colorlog\n",
    "import src.prepare  # noqa\n",
    "import logging.config\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.config import read_config\n",
    "from hydra.utils import instantiate\n",
    "from src.load import load_model_from_cfg\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f946cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_CONFIG = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'formatters': {\n",
    "        'simple': {\n",
    "            'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s',\n",
    "            'datefmt': '%d/%m/%y %H:%M:%S',\n",
    "        },\n",
    "        'colorlog': {\n",
    "            '()': 'colorlog.ColoredFormatter',\n",
    "            'format': '[%(white)s%(asctime)s%(reset)s] %(log_color)s%(levelname)s%(reset)s   %(message)s',\n",
    "            'datefmt': '%d/%m/%y %H:%M:%S',\n",
    "            'log_colors': {\n",
    "                'DEBUG': 'purple',\n",
    "                'INFO': 'blue',\n",
    "                'WARNING': 'yellow',\n",
    "                'ERROR': 'red',\n",
    "                'CRITICAL': 'red',\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"logger has been configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4126b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**source:** [hydra configurations in a notebook](https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4e2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIRS = [\n",
    "    \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats_16\",\n",
    "    \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats_32\",\n",
    "    \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats_64\",\n",
    "    \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats_128\",\n",
    "    \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats_256\",\n",
    "    \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats_512\",\n",
    "]\n",
    "\n",
    "RUN_DIR = \"/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f37f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hydra:\n",
      "  run:\n",
      "    dir: ${run_dir}\n",
      "  sweep:\n",
      "    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}\n",
      "    subdir: ${hydra.job.num}\n",
      "  launcher:\n",
      "    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher\n",
      "  sweeper:\n",
      "    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper\n",
      "    max_batch_size: null\n",
      "    params: null\n",
      "  help:\n",
      "    app_name: ${hydra.job.name}\n",
      "    header: '${hydra.help.app_name} is powered by Hydra.\n",
      "\n",
      "      '\n",
      "    footer: 'Powered by Hydra (https://hydra.cc)\n",
      "\n",
      "      Use --hydra-help to view Hydra specific help\n",
      "\n",
      "      '\n",
      "    template: '${hydra.help.header}\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (group=option)\n",
      "\n",
      "\n",
      "      $APP_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      == Config ==\n",
      "\n",
      "      Override anything in the config (foo.bar=value)\n",
      "\n",
      "\n",
      "      $CONFIG\n",
      "\n",
      "\n",
      "      ${hydra.help.footer}\n",
      "\n",
      "      '\n",
      "  hydra_help:\n",
      "    template: 'Hydra (${hydra.runtime.version})\n",
      "\n",
      "      See https://hydra.cc for more info.\n",
      "\n",
      "\n",
      "      == Flags ==\n",
      "\n",
      "      $FLAGS_HELP\n",
      "\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (For example, append hydra/job_logging=disabled\n",
      "      to command line)\n",
      "\n",
      "\n",
      "      $HYDRA_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      Use ''--cfg hydra'' to Show the Hydra config.\n",
      "\n",
      "      '\n",
      "    hydra_help: ???\n",
      "  hydra_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      verysimple:\n",
      "        format: '%(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: src.logging.TqdmLoggingHandler\n",
      "        formatter: verysimple\n",
      "    root:\n",
      "      level: ${logger_level}\n",
      "      handlers:\n",
      "      - console\n",
      "    disable_existing_loggers: false\n",
      "  job_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "        datefmt: '%d/%m/%y %H:%M:%S'\n",
      "      colorlog:\n",
      "        (): colorlog.ColoredFormatter\n",
      "        format: '[%(white)s%(asctime)s%(reset)s] %(log_color)s%(levelname)s%(reset)s   %(message)s'\n",
      "        datefmt: '%d/%m/%y %H:%M:%S'\n",
      "        log_colors:\n",
      "          DEBUG: purple\n",
      "          INFO: blue\n",
      "          WARNING: yellow\n",
      "          ERROR: red\n",
      "          CRITICAL: red\n",
      "    handlers:\n",
      "      console:\n",
      "        class: src.logging.TqdmLoggingHandler\n",
      "        formatter: colorlog\n",
      "      file_out:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: ${run_dir}/${hydra.job.name}.out\n",
      "    root:\n",
      "      level: ${logger_level}\n",
      "      handlers:\n",
      "      - console\n",
      "      - file_out\n",
      "    disable_existing_loggers: false\n",
      "  env: {}\n",
      "  mode: null\n",
      "  searchpath: []\n",
      "  callbacks: {}\n",
      "  output_subdir: .hydra\n",
      "  overrides:\n",
      "    hydra: []\n",
      "    task:\n",
      "    - run_dir=/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats\n",
      "  job:\n",
      "    name: notebook\n",
      "    chdir: null\n",
      "    override_dirname: run_dir=/home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats\n",
      "    id: ???\n",
      "    num: ???\n",
      "    config_name: evaluate-classifier\n",
      "    env_set: {}\n",
      "    env_copy: []\n",
      "    config:\n",
      "      override_dirname:\n",
      "        kv_sep: '='\n",
      "        item_sep: ','\n",
      "        exclude_keys: []\n",
      "  runtime:\n",
      "    version: 1.3.2\n",
      "    version_base: '1.3'\n",
      "    cwd: /media/rana/nadir/codes/tmr-code\n",
      "    config_sources:\n",
      "    - path: hydra.conf\n",
      "      schema: pkg\n",
      "      provider: hydra\n",
      "    - path: /media/rana/nadir/codes/tmr-code/configs\n",
      "      schema: file\n",
      "      provider: main\n",
      "    - path: hydra_plugins.hydra_colorlog.conf\n",
      "      schema: pkg\n",
      "      provider: hydra-colorlog\n",
      "    - path: ''\n",
      "      schema: structured\n",
      "      provider: schema\n",
      "    output_dir: ???\n",
      "    choices:\n",
      "      model: classifier\n",
      "      data: babel-classifier\n",
      "      data/motion_loader: guoh3dfeats\n",
      "      hydra/env: default\n",
      "      hydra/callbacks: null\n",
      "      hydra/job_logging: tqdm\n",
      "      hydra/hydra_logging: tqdm\n",
      "      hydra/hydra_help: default\n",
      "      hydra/help: default\n",
      "      hydra/sweeper: basic\n",
      "      hydra/launcher: basic\n",
      "      hydra/output: default\n",
      "  verbose: false\n",
      "data:\n",
      "  motion_loader:\n",
      "    _target_: src.data.motion.AMASSMotionLoader\n",
      "    base_dir: datasets/motions/guoh3dfeats\n",
      "    normalizer:\n",
      "      _target_: src.data.motion.Normalizer\n",
      "      base_dir: stats/${hydra:runtime.choices.data}/${hydra:runtime.choices.data/motion_loader}\n",
      "      eps: 1.0e-12\n",
      "    fps: 20.0\n",
      "    nfeats: 263\n",
      "  _target_: src.data.text_motion.TextMotionDataset\n",
      "  path: datasets/annotations/${hydra:runtime.choices.data}\n",
      "  text_to_token_emb:\n",
      "    _target_: src.data.text.TokenEmbeddings\n",
      "    path: datasets/annotations/${hydra:runtime.choices.data}\n",
      "    modelname: distilbert-base-uncased\n",
      "    preload: true\n",
      "  text_to_sent_emb:\n",
      "    _target_: src.data.text.SentenceEmbeddings\n",
      "    path: datasets/annotations/${hydra:runtime.choices.data}\n",
      "    modelname: sentence-transformers/all-mpnet-base-v2\n",
      "    preload: true\n",
      "  preload: false\n",
      "  mode: classifier\n",
      "model:\n",
      "  _target_: src.model.ClassifierModel\n",
      "  motion_encoder:\n",
      "    _target_: src.model.ACTORStyleEncoder\n",
      "    nfeats: ${data.motion_loader.nfeats}\n",
      "    vae: true\n",
      "    latent_dim: 256\n",
      "    ff_size: 1024\n",
      "    num_layers: 6\n",
      "    num_heads: 4\n",
      "    dropout: 0.1\n",
      "    activation: gelu\n",
      "  hidden_dim: ??\n",
      "  lr: 0.0001\n",
      "  cache: true\n",
      "run_dir: /home/nadir/disk/codes/tmr-code/outputs/classifier_babel-classifier_guoh3dfeats\n",
      "seed: 1234\n",
      "logger_level: INFO\n",
      "device: cuda:1\n",
      "ckpt: last\n",
      "dataloader:\n",
      "  _target_: torch.utils.data.DataLoader\n",
      "  batch_size: 8\n",
      "  num_workers: 8\n",
      "examples: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(\n",
    "    version_base=None,\n",
    "    config_path=\"configs\",\n",
    "    # \n",
    "):\n",
    "    # config = compose(overrides=[\"+db=mysql\"])\n",
    "    config = compose(\n",
    "        config_name=\"evaluate-classifier\",\n",
    "        return_hydra_config=True,\n",
    "        overrides=[f\"run_dir={RUN_DIR}\"]\n",
    "    )\n",
    "    \n",
    "    from hydra.core.hydra_config import HydraConfig\n",
    "    \n",
    "    HydraConfig.instance().set_config(config)\n",
    "    \n",
    "print(OmegaConf.to_yaml(config, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f049f0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model-variant]: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[evaluate-classification]: 100%|██████████| 655/655 [01:19<00:00,  8.27it/s]\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy]: 82.53%\n",
      "[precision]: 79.59%\n",
      "[recall]: 76.99%\n",
      "[f1]: 78.07%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.63      0.68      1542\n",
      "         1.0       0.86      0.90      0.88      3691\n",
      "\n",
      "    accuracy                           0.83      5233\n",
      "   macro avg       0.80      0.77      0.78      5233\n",
      "weighted avg       0.82      0.83      0.82      5233\n",
      "\n",
      "--- --- ---\n",
      "--- --- ---\n",
      "[[ 979  563]\n",
      " [ 351 3340]]\n",
      "--- --- ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[error]: Error(s) in loading state_dict for Sequential:\n",
      "\tsize mismatch for 0.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).\n",
      "\tsize mismatch for 0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for 2.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model-variant]: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[evaluate-classification]: 100%|██████████| 655/655 [01:19<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy]: 81.37%\n",
      "[precision]: 77.66%\n",
      "[recall]: 77.05%\n",
      "[f1]: 77.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.67      0.68      1542\n",
      "         1.0       0.86      0.88      0.87      3691\n",
      "\n",
      "    accuracy                           0.81      5233\n",
      "   macro avg       0.78      0.77      0.77      5233\n",
      "weighted avg       0.81      0.81      0.81      5233\n",
      "\n",
      "--- --- ---\n",
      "--- --- ---\n",
      "[[1026  516]\n",
      " [ 459 3232]]\n",
      "--- --- ---\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model-variant]: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[evaluate-classification]: 100%|██████████| 655/655 [01:19<00:00,  8.25it/s]\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy]: 81.10%\n",
      "[precision]: 77.28%\n",
      "[recall]: 77.18%\n",
      "[f1]: 77.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.68      0.68      1542\n",
      "         1.0       0.87      0.87      0.87      3691\n",
      "\n",
      "    accuracy                           0.81      5233\n",
      "   macro avg       0.77      0.77      0.77      5233\n",
      "weighted avg       0.81      0.81      0.81      5233\n",
      "\n",
      "--- --- ---\n",
      "--- --- ---\n",
      "[[1043  499]\n",
      " [ 490 3201]]\n",
      "--- --- ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[model-variant]: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[evaluate-classification]: 100%|██████████| 655/655 [01:21<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy]: 81.92%\n",
      "[precision]: 78.56%\n",
      "[recall]: 76.86%\n",
      "[f1]: 77.61%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.65      0.68      1542\n",
      "         1.0       0.86      0.89      0.87      3691\n",
      "\n",
      "    accuracy                           0.82      5233\n",
      "   macro avg       0.79      0.77      0.78      5233\n",
      "weighted avg       0.82      0.82      0.82      5233\n",
      "\n",
      "--- --- ---\n",
      "--- --- ---\n",
      "[[ 995  547]\n",
      " [ 399 3292]]\n",
      "--- --- ---\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model-variant]: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[evaluate-classification]: 100%|██████████| 655/655 [01:21<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy]: 81.88%\n",
      "[precision]: 78.49%\n",
      "[recall]: 76.91%\n",
      "[f1]: 77.61%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.65      0.68      1542\n",
      "         1.0       0.86      0.89      0.87      3691\n",
      "\n",
      "    accuracy                           0.82      5233\n",
      "   macro avg       0.78      0.77      0.78      5233\n",
      "weighted avg       0.81      0.82      0.82      5233\n",
      "\n",
      "--- --- ---\n",
      "--- --- ---\n",
      "[[ 999  543]\n",
      " [ 405 3286]]\n",
      "--- --- ---\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for run_dir in RUN_DIRS:\n",
    "    try:\n",
    "        logger.info(f\"[run_dir]: {run_dir}\")\n",
    "        print(f\"[model-variant]: {run_dir.split('_')[-1]}\")\n",
    "        \n",
    "        device = config.device\n",
    "        # run_dir = config.run_dir\n",
    "        examples = config.examples\n",
    "        ckpt_name = config.ckpt\n",
    "\n",
    "        # save_dir = os.path.join(run_dir, \"segmentation-evaluation\")\n",
    "        # os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # NOTE: moved up here in order to use the segmentation config for the dataset\n",
    "        # defined in the config file rather than the config used to train the model\n",
    "        dataset = instantiate(config.data, mode=\"classic\", split=\"test\")\n",
    "\n",
    "        # NOTE: will load the config used to train the model\n",
    "        cfg = read_config(run_dir)\n",
    "\n",
    "        pl.seed_everything(cfg.seed)\n",
    "\n",
    "        logger.info(\"[model]: loading\")\n",
    "        model = load_model_from_cfg(cfg, ckpt_name, eval_mode=True, device=device)\n",
    "\n",
    "        logger.info(f\"[dataset.mode]: {dataset.mode}\")\n",
    "\n",
    "        dataloader = instantiate(\n",
    "            cfg.dataloader,\n",
    "            dataset=dataset,\n",
    "            collate_fn=dataset.collate_fn,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"[#dataloader]: {len(dataset)}\")\n",
    "        logger.info(f\"[dataloader.batch_size]: {dataloader.batch_size}\")\n",
    "\n",
    "        model = model.eval()\n",
    "        \n",
    "        all_predictions, all_labels = [], []\n",
    "                \n",
    "        from src.model import ClassifierModel\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for index, batch in tqdm.tqdm(iterable=enumerate(dataloader), total=len(dataloader), desc=\"[evaluate-classification]\"):\n",
    "                batch[\"motion_x_dict\"][\"x\"] = batch[\"motion_x_dict\"][\"x\"].to(device)\n",
    "                batch[\"motion_x_dict\"][\"mask\"] = batch[\"motion_x_dict\"][\"mask\"].to(device)\n",
    "                \n",
    "                outputs = model(batch, None)\n",
    "                \n",
    "                labels = ClassifierModel.get_targets(batch, None)\n",
    "                predictions = (torch.sigmoid(outputs) > 0.5).long().cpu().numpy()\n",
    "                \n",
    "                for prediction, label in zip(predictions, labels):\n",
    "                    all_predictions.append(prediction)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "        from src.model.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        # TODO: compute balanced accuracy score\n",
    "        accuracy = accuracy_score(all_predictions, all_labels)\n",
    "        precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "        recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "        report = classification_report(all_labels, all_predictions, zero_division=0)\n",
    "\n",
    "        print(f\"[accuracy]: {(accuracy * 100):.02f}%\")\n",
    "        print(f\"[precision]: {(precision * 100):.02f}%\")\n",
    "        print(f\"[recall]: {(recall * 100):.02f}%\")\n",
    "        print(f\"[f1]: {(f1 * 100):.02f}%\")\n",
    "        print(report)\n",
    "        \n",
    "        print(\"--- --- ---\")\n",
    "        \n",
    "        from sklearn.metrics import confusion_matrix as generate_confusion_matrix\n",
    "\n",
    "        confusion_matrix = generate_confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        print(\"--- --- ---\")\n",
    "        \n",
    "        print(confusion_matrix)\n",
    "        \n",
    "        print(\"--- --- ---\\n\\n\\n\\n\")\n",
    "    except Exception as exception:\n",
    "        print(f\"[error]: {exception}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tmr.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
