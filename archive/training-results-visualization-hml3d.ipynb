{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e394716",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b09cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadir/tmr-code/.tmr.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tqdm\n",
    "import json\n",
    "import torch\n",
    "import hydra\n",
    "import pprint\n",
    "import logging\n",
    "import colorlog\n",
    "import src.prepare  # noqa\n",
    "import logging.config\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.config import read_config\n",
    "from hydra.utils import instantiate\n",
    "from src.load import load_model_from_cfg\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc061f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_CONFIG = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'formatters': {\n",
    "        'simple': {\n",
    "            'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s',\n",
    "            'datefmt': '%d/%m/%y %H:%M:%S',\n",
    "        },\n",
    "        'colorlog': {\n",
    "            '()': 'colorlog.ColoredFormatter',\n",
    "            'format': '[%(white)s%(asctime)s%(reset)s] %(log_color)s%(levelname)s%(reset)s   %(message)s',\n",
    "            'datefmt': '%d/%m/%y %H:%M:%S',\n",
    "            'log_colors': {\n",
    "                'DEBUG': 'purple',\n",
    "                'INFO': 'blue',\n",
    "                'WARNING': 'yellow',\n",
    "                'ERROR': 'red',\n",
    "                'CRITICAL': 'red',\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"logger has been configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec33bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIRS = [\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_20\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_25\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_30\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_35\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_40\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_45\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_50\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_20\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_25\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_30\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_35\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_40\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_45\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_False_mlp_50\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_20\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_25\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_30\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_35\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_40\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_45\",\n",
    "    \"/home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_tmr_True_mlp_50\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81955573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segmentation_metrics(output_path):\n",
    "    \"\"\"Load segmentation evaluation metrics from JSON file\"\"\"\n",
    "    metrics_path = os.path.join(output_path, \"segmentation-evaluation\", \"metrics.json\")\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(metrics_path):\n",
    "            with open(metrics_path, \"r\") as f:\n",
    "                return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading metrics from {output_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_model_info(output_path):\n",
    "    \"\"\"Parse model information from output path\"\"\"\n",
    "    parts = os.path.basename(output_path).split('_')\n",
    "    encoder_type = parts[1]  # stgcn or tmr\n",
    "    pretrained = parts[2] == 'True'\n",
    "    window_size = int(parts[4])\n",
    "    \n",
    "    if encoder_type == 'stgcn':\n",
    "        model_name = \"ST-GCN\"\n",
    "    elif encoder_type == 'tmr' and not pretrained:\n",
    "        model_name = \"TMR (no pretraining)\"\n",
    "    else:  # tmr with pretraining\n",
    "        model_name = \"TMR (with pretraining)\"\n",
    "    \n",
    "    return model_name, window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1972c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(index: int):\n",
    "    with initialize(\n",
    "        version_base=None,\n",
    "        config_path=\"configs\",\n",
    "        # \n",
    "    ):\n",
    "        # config = compose(overrides=[\"+db=mysql\"])\n",
    "        config = compose(\n",
    "            config_name=\"evaluate-start-end-segmentation-segmenter\",\n",
    "            return_hydra_config=True,\n",
    "            overrides=[f\"run_dir={RUN_DIRS[index]}\"]\n",
    "        )\n",
    "        \n",
    "        from hydra.core.hydra_config import HydraConfig\n",
    "        \n",
    "        HydraConfig.instance().set_config(config)\n",
    "        \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3e73029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(config, with_seeding=True, pretrained=True):\n",
    "    device = config.device\n",
    "    run_dir = config.run_dir\n",
    "    examples = config.examples\n",
    "    ckpt_name = config.ckpt\n",
    "\n",
    "    save_dir = os.path.join(run_dir, \"segmentation-evaluation\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"[config.data]:\", config.data)\n",
    "    \n",
    "    window_size = int(run_dir.split(\"_mlp_\")[1])\n",
    "\n",
    "    # NOTE: moved up here in order to use the segmentation config for the dataset\n",
    "    # defined in the config file rather than the config used to train the model\n",
    "    dataset = instantiate(\n",
    "        config.data,\n",
    "        dir=\"/home/nadir/disk/datasets/babel-for-validation\",\n",
    "        window_size=window_size,\n",
    "        split=\"all\",\n",
    "        for_validation=True,\n",
    "        normalize=False,\n",
    "    )\n",
    "    \n",
    "    normalization_statistics = torch.load(os.path.join(dataset.dir, \"motion_normalization_stats.pt\"))\n",
    "\n",
    "    mean = normalization_statistics[\"mean\"]\n",
    "    std = normalization_statistics[\"std\"]\n",
    "    \n",
    "    print(\"[mean.shape]:\", mean.shape)\n",
    "    print(\"[std.shape]:\", std.shape)\n",
    "\n",
    "    # NOTE: will load the config used to train the model\n",
    "    \n",
    "    cfg = read_config(run_dir)\n",
    "\n",
    "    pl.seed_everything(cfg.seed)\n",
    "\n",
    "    logger.info(\"[model]: loading\")\n",
    "    model = load_model_from_cfg(cfg, ckpt_name, eval_mode=True, device=device, pretrained=pretrained)\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    return model, dataset, device, window_size, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3f0a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[config.run_dir]: /home/nadir/tmr-code/outputs/archives/snapshot-06-02-16:30/start-end-segmentation_stgcn_False_mlp_40\n",
      "[metrics]: {'framewise_accuracy': 0.7621569405453676, 'edit_score': 0.7651706095200113, 'f1_scores': {'f1@0.10': 0.6603825840469434, 'f1@0.20': 0.615270252578462, 'f1@0.30': 0.5765571707735224, 'f1@0.40': 0.5480669932665598, 'f1@0.50': 0.5165402440375978, 'f1@0.60': 0.48890871919347767, 'f1@0.70': 0.4568678212568927, 'f1@0.80': 0.4258077881199871, 'f1@0.90': 0.3860288800315932, 'f1@1.00': 0.3495424804581183}, 'balanced_accuracy': 0.6184430357883799, 'matthews_corrcoef': 0.17033563098183793, 'per_class': {'0.0': {'precision': 0.9269705781059956, 'recall': 0.7972098498822753, 'f1': 0.8572073588370345}, '1.0': {'precision': 0.19551119969063271, 'recall': 0.4396762216944844, 'f1': 0.2706653900402549}}}\n",
      "[config.data]: {'_target_': 'src.data.windowed_dataset.WindowedDataset', 'dir': '???', 'window_size': '???', 'preload': False, 'normalize': False}\n",
      "[mean.shape]: torch.Size([22, 3])\n",
      "[std.shape]: torch.Size([22, 3])\n",
      "[#dataset]: 1538\n"
     ]
    }
   ],
   "source": [
    "# config = get_config(18)\n",
    "config = get_config(4)\n",
    "# config = get_config(2)\n",
    "\n",
    "metrics = load_segmentation_metrics(config.run_dir)\n",
    "\n",
    "print(\"[config.run_dir]:\", config.run_dir)\n",
    "print(\"[metrics]:\", metrics)\n",
    "\n",
    "model, dataset, device, window_size, mean, std = prepare(config, pretrained=True)\n",
    "\n",
    "print(\"[#dataset]:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c5b870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[treatment]: found 1810 AMASS samples in HML3D but not in BABEL.\n",
      "[missing_in_babel]: ['ACCAD/Female1General_c3d/A12 - crawl backwards_poses', 'ACCAD/Female1Running_c3d/C25 -  side step right_poses', 'ACCAD/Female1Walking_c3d/B20 - walk with box_poses', 'ACCAD/Female1Walking_c3d/B21 s3 - put down box to walk_poses', 'ACCAD/Male1Walking_c3d/Walk B15 - Walk turn around_poses', 'ACCAD/Male1Walking_c3d/Walk B22 - Side step left_poses', 'ACCAD/Male2MartialArtsKicks_c3d/G17-  push kick left_poses', 'ACCAD/Male2MartialArtsPunches_c3d/E14 - body cross right_poses', 'ACCAD/Male2MartialArtsStances_c3d/D5 - ready to walk away_poses', 'ACCAD/Male2Running_c3d/C1 - stand to run_poses']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "amass_to_hml3d_path = \"/home/nadir/code/babel/amass-to-hml3d.csv\"\n",
    "amass_to_babel_path = \"/home/nadir/code/babel/amass-to-babel.json\"\n",
    "\n",
    "def find_amass_in_hml3d_not_in_babel(csv_path, json_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    hml3d_paths = df['source_path'].apply(lambda x: x.replace('./pose_data/', '').replace('_poses.npy', '_poses'))\n",
    "    hml3d_set = set(hml3d_paths)\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        babel_data = json.load(f)\n",
    "        \n",
    "    babel_set = set(babel_data.keys())\n",
    "\n",
    "    only_in_hml3d = sorted(hml3d_set - babel_set)\n",
    "\n",
    "    return only_in_hml3d\n",
    "\n",
    "missing_in_babel = find_amass_in_hml3d_not_in_babel(amass_to_hml3d_path, amass_to_babel_path)\n",
    "\n",
    "print(f\"[treatment]: found {len(missing_in_babel)} AMASS samples in HML3D but not in BABEL.\")\n",
    "\n",
    "print(\"[missing_in_babel]:\", missing_in_babel[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52bf8a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hml3d_sample.keys()]: dict_keys(['file_id', 'amass_relative_path', 'motion', 'transformed_motion', 'annotations', 'index'])\n",
      "[outputs.shape]: torch.Size([199])\n",
      "[annotations]: ['a oerson wals forward and backward on a diagonal line.#a/DET oerson/NOUN wal/NOUN forward/ADV and/CCONJ backward/ADV on/ADP a/DET diagonal/ADJ line/NOUN#0.0#0.0', 'a person walks forward and backward twice.#a/DET person/NOUN walk/VERB forward/ADV and/CCONJ backward/ADV twice/ADV#0.0#0.0', 'he walks forward, then turning left, he backs up in a slight arc back to his start point, then walks diagonally to his right, turns to his left, takes a step or two backward, turns, and walks the same diagonal back.#he/PRON walk/VERB forward/ADV then/ADV turn/VERB left/ADV he/PRON back/VERB up/ADP in/ADP a/DET slight/ADJ arc/NOUN back/ADV to/ADP his/DET start/NOUN point/NOUN then/ADV walk/VERB diagonally/ADV to/ADP his/DET right/NOUN turn/VERB to/ADP his/DET left/NOUN take/VERB a/DET step/NOUN or/CCONJ two/NUM backward/ADJ turn/VERB and/CCONJ walk/VERB the/DET same/ADJ diagonal/ADJ back/NOUN#0.0#0.0']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join(\"/home/nadir/tmr-code/archive/samples/\", np.random.choice(os.listdir(\"/home/nadir/tmr-code/archive/samples/\")))\n",
    "\n",
    "hml3d_sample = np.load(path, allow_pickle=True).item()\n",
    "\n",
    "print(\"[hml3d_sample.keys()]:\", hml3d_sample.keys())\n",
    "\n",
    "sample = {\n",
    "    \"motion\": torch.tensor(hml3d_sample[\"transformed_motion\"], dtype=torch.float32).to(device),\n",
    "    \"transformed_motion\": torch.tensor(hml3d_sample[\"motion\"], dtype=torch.float32).to(device),\n",
    "}\n",
    "\n",
    "outputs, exception = model.segment_sequence(\n",
    "    sample,\n",
    "    window_size=window_size,\n",
    "    window_step=1,\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n",
    "\n",
    "if exception is not None:\n",
    "    logger.warning(f\"[skipped-sequence]: {path} due to {exception}\")\n",
    "\n",
    "print(\"[outputs.shape]:\", outputs.shape)\n",
    "\n",
    "preds = outputs.cpu().numpy()\n",
    "\n",
    "print(\"[annotations]:\", hml3d_sample[\"annotations\"])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tas_helpers.visualization import SegmentationVisualizer\n",
    "from tas_helpers.utils import (\n",
    "    frame_level_annotations_to_segment_level_annotations,\n",
    ")\n",
    "\n",
    "visualizer = SegmentationVisualizer(labels_values=[0, 1])\n",
    "\n",
    "visualizer.plot_segmentation(preds, header=\"Ground Truth\", fps=20, show_ticks=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tmr.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
